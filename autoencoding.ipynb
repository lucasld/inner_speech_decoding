{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "\n",
    "import data_preprocessing as dp\n",
    "import utilities\n",
    "import models.training as train\n",
    "from models.autoencoder import ConvolutionalAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'augmented_ds_bs3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_pipe(data, events):\n",
    "    aug_data = np.copy(data)\n",
    "    for i in range(aug_data.shape[0]):\n",
    "        aug_data[i] = np.fliplr(aug_data[i]) if np.random.rand() < 0.5 else np.flipud(aug_data[i])\n",
    "    aug_data = np.concatenate((aug_data, np.copy(data)))\n",
    "    events = np.concatenate((events, events))\n",
    "    aug_data = aug_data + np.random.normal(0, 0.2, aug_data.shape)\n",
    "\n",
    "    return aug_data, np.concatenate((data, data)), events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[0m\u001b[38;2;255;0;0m#\u001b[38;2;252;2;0m#\u001b[38;2;249;5;0m#\u001b[38;2;247;7;0m#\u001b[38;2;244;10;0m#\u001b[38;2;242;12;0m#\u001b[38;2;239;15;0m#\u001b[38;2;237;17;0m#\u001b[38;2;234;20;0m#\u001b[38;2;232;22;0m#\u001b[38;2;229;25;0m#\u001b[38;2;226;28;0m#\u001b[38;2;224;30;0m#\u001b[38;2;221;33;0m#\u001b[38;2;219;35;0m#\u001b[38;2;216;38;0m#\u001b[38;2;214;40;0m#\u001b[38;2;211;43;0m#\u001b[38;2;209;45;0m#\u001b[38;2;206;48;0m#\u001b[38;2;204;51;0m#\u001b[38;2;201;53;0m#\u001b[38;2;198;56;0m#\u001b[38;2;196;58;0m#\u001b[38;2;193;61;0m#\u001b[38;2;191;63;0m#\u001b[38;2;188;66;0m#\u001b[38;2;186;68;0m#\u001b[38;2;183;71;0m#\u001b[38;2;181;73;0m#\u001b[38;2;178;76;0m#\u001b[38;2;175;79;0m#\u001b[38;2;173;81;0m#\u001b[38;2;170;84;0m#\u001b[38;2;168;86;0m#\u001b[38;2;165;89;0m#\u001b[38;2;163;91;0m#\u001b[38;2;160;94;0m#\u001b[38;2;158;96;0m#\u001b[38;2;155;99;0m#\u001b[38;2;153;102;0m#\u001b[38;2;150;104;0m#\u001b[38;2;147;107;0m#\u001b[38;2;145;109;0m#\u001b[38;2;142;112;0m#\u001b[38;2;140;114;0m#\u001b[38;2;137;117;0m#\u001b[38;2;135;119;0m#\u001b[38;2;132;122;0m#\u001b[38;2;130;124;0m#\u001b[38;2;127;127;0m#\u001b[38;2;124;130;0m#\u001b[38;2;122;132;0m#\u001b[38;2;119;135;0m#\u001b[38;2;117;137;0m#\u001b[38;2;114;140;0m#\u001b[38;2;112;142;0m#\u001b[38;2;109;145;0m#\u001b[38;2;107;147;0m#\u001b[38;2;104;150;0m#\u001b[38;2;102;153;0m#\u001b[38;2;99;155;0m#\u001b[38;2;96;158;0m#\u001b[38;2;94;160;0m#\u001b[38;2;91;163;0m#\u001b[38;2;89;165;0m#\u001b[38;2;86;168;0m#\u001b[38;2;84;170;0m#\u001b[38;2;81;173;0m#\u001b[38;2;79;175;0m#\u001b[38;2;76;178;0m#\u001b[38;2;73;181;0m#\u001b[38;2;71;183;0m#\u001b[38;2;68;186;0m#\u001b[38;2;66;188;0m#\u001b[38;2;63;191;0m#\u001b[38;2;61;193;0m#\u001b[38;2;58;196;0m#\u001b[38;2;56;198;0m#\u001b[38;2;53;201;0m#\u001b[38;2;50;204;0m#\u001b[38;2;48;206;0m#\u001b[38;2;45;209;0m#\u001b[38;2;43;211;0m#\u001b[38;2;40;214;0m#\u001b[38;2;38;216;0m#\u001b[38;2;35;219;0m#\u001b[38;2;33;221;0m#\u001b[38;2;30;224;0m#\u001b[38;2;28;226;0m#\u001b[38;2;25;229;0m#\u001b[38;2;22;232;0m#\u001b[38;2;20;234;0m#\u001b[38;2;17;237;0m#\u001b[38;2;15;239;0m#\u001b[38;2;12;242;0m#\u001b[38;2;10;244;0m#\u001b[38;2;7;247;0m#\u001b[38;2;5;249;0m#\u001b[38;2;2;252;0m#\u001b[0m]\u001b[0m100%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 15:00:41.158304: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-16 15:00:41.158445: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 15:00:41.534352: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "tf.config.set_soft_device_placement(True) \n",
    "dp.create_datasets(f'dataset/preprocessed/{title}', batch_size=3, augmentation_pipeline=augment_pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset to train the Autoencoder\n",
    "\n",
    "```python\n",
    "if 2 == 2:\n",
    "    print(\"Halllo\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "datasets = {key:tf.data.experimental.load(f'dataset/preprocessed/{title}/{key}') for key in ('train', 'test', 'valid')}\n",
    "autoencoder_datasets = {key:ds.map(lambda input, clean_input, target: (input, clean_input)) for key, ds in datasets.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib tk\n",
    "autoencoder = ConvolutionalAutoencoder()\n",
    "autoencoder.build((None, 128,640,1))\n",
    "autoencoder.summary()\n",
    "\n",
    "for _input, target in datasets['train'].take(np.random.randint(0,200)):\n",
    "    out = autoencoder(_input)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(_input[0][:,:,0])\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(out[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 14:40:55.552129: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-16 14:40:55.624794: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\r"
     ]
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "# Initialize the loss-function\n",
    "loss_func = tf.keras.losses.MeanSquaredError()\n",
    "# Initialize the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# Initialize Train-Object\n",
    "trainer = train.Trainer(autoencoder, autoencoder_datasets, optimizer, loss_func)\n",
    "# Initialize Plotting-Object\n",
    "grapher = utilities.TrainingGrapher(2,1, supxlabel='Epochs', axs_xlabels=[['train loss', 'test loss']])\n",
    "\n",
    "trainer.model_test()\n",
    "for epoch in range(20):\n",
    "    print(epoch, end='\\r')  \n",
    "    trainer.train_epoch()\n",
    "    grapher.update([trainer.losses['train'], trainer.losses['test']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "#grapher.fig.set_size_inches(15, 8)\n",
    "grapher.fig.savefig(\"apple.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "for i, t in autoencoder_datasets['train'].take(8):\n",
    "    out_enc = autoencoder.encoder(i)\n",
    "    out_dec = autoencoder.decoder(out_enc)\n",
    "    f, axs = plt.subplots(1,4,figsize=(15,15))\n",
    "    axs[0].imshow(i[0][:,:,0])\n",
    "    axs[1].imshow(t[0][:,:,0])\n",
    "    axs[2].imshow(out_dec[0][:,:,0])\n",
    "    # normalize each channel\n",
    "    norm_enc = out_enc[0] / np.max(out_enc[0], (0, 1))[np.newaxis, np.newaxis, :]\n",
    "    axs[3].imshow(norm_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 14:49:11.970218: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/saved_models/augmented_ds_bs3/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "autoencoder.save(f'./models/saved_models/{title}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca8d0a0b18e5ead98978c779fcc98c2ce0d58c7314eef98ffee0524dd190160b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
