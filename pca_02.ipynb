{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import data_preprocessing as dp\n",
    "import utilities\n",
    "import models.training as train\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001B[0m\u001B[38;2;255;0;0m#\u001B[38;2;252;2;0m#\u001B[38;2;249;5;0m#\u001B[38;2;247;7;0m#\u001B[38;2;244;10;0m#\u001B[38;2;242;12;0m#\u001B[38;2;239;15;0m#\u001B[38;2;237;17;0m#\u001B[38;2;234;20;0m#\u001B[38;2;232;22;0m#\u001B[38;2;229;25;0m#\u001B[38;2;226;28;0m#\u001B[38;2;224;30;0m#\u001B[38;2;221;33;0m#\u001B[38;2;219;35;0m#\u001B[38;2;216;38;0m#\u001B[38;2;214;40;0m#\u001B[38;2;211;43;0m#\u001B[38;2;209;45;0m#\u001B[38;2;206;48;0m#\u001B[38;2;204;51;0m#\u001B[38;2;201;53;0m#\u001B[38;2;198;56;0m#\u001B[38;2;196;58;0m#\u001B[38;2;193;61;0m#\u001B[38;2;191;63;0m#\u001B[38;2;188;66;0m#\u001B[38;2;186;68;0m#\u001B[38;2;183;71;0m#\u001B[38;2;181;73;0m#\u001B[38;2;178;76;0m#\u001B[38;2;175;79;0m#\u001B[38;2;173;81;0m#\u001B[38;2;170;84;0m#\u001B[38;2;168;86;0m#\u001B[38;2;165;89;0m#\u001B[38;2;163;91;0m#\u001B[38;2;160;94;0m#\u001B[38;2;158;96;0m#\u001B[38;2;155;99;0m#\u001B[38;2;153;102;0m#\u001B[38;2;150;104;0m#\u001B[38;2;147;107;0m#\u001B[38;2;145;109;0m#\u001B[38;2;142;112;0m#\u001B[38;2;140;114;0m#\u001B[38;2;137;117;0m#\u001B[38;2;135;119;0m#\u001B[38;2;132;122;0m#\u001B[38;2;130;124;0m#\u001B[38;2;127;127;0m#\u001B[38;2;124;130;0m#\u001B[38;2;122;132;0m#\u001B[38;2;119;135;0m#\u001B[38;2;117;137;0m#\u001B[38;2;114;140;0m#\u001B[38;2;112;142;0m#\u001B[38;2;109;145;0m#\u001B[38;2;107;147;0m#\u001B[38;2;104;150;0m#\u001B[38;2;102;153;0m#\u001B[38;2;99;155;0m#\u001B[38;2;96;158;0m#\u001B[38;2;94;160;0m#\u001B[38;2;91;163;0m#\u001B[38;2;89;165;0m#\u001B[38;2;86;168;0m#\u001B[38;2;84;170;0m#\u001B[38;2;81;173;0m#\u001B[38;2;79;175;0m#\u001B[38;2;76;178;0m#\u001B[38;2;73;181;0m#\u001B[38;2;71;183;0m#\u001B[38;2;68;186;0m#\u001B[38;2;66;188;0m#\u001B[38;2;63;191;0m#\u001B[38;2;61;193;0m#\u001B[38;2;58;196;0m#\u001B[38;2;56;198;0m#\u001B[38;2;53;201;0m#\u001B[38;2;50;204;0m#\u001B[38;2;48;206;0m#\u001B[38;2;45;209;0m#\u001B[38;2;43;211;0m#\u001B[38;2;40;214;0m#\u001B[38;2;38;216;0m#\u001B[38;2;35;219;0m#\u001B[38;2;33;221;0m#\u001B[38;2;30;224;0m#\u001B[38;2;28;226;0m#\u001B[38;2;25;229;0m#\u001B[38;2;22;232;0m#\u001B[38;2;20;234;0m#\u001B[38;2;17;237;0m#\u001B[38;2;15;239;0m#\u001B[38;2;12;242;0m#\u001B[38;2;10;244;0m#\u001B[38;2;7;247;0m#\u001B[38;2;5;249;0m#\u001B[38;2;2;252;0m#\u001B[0m]\u001B[0m100%\r"
     ]
    }
   ],
   "source": [
    "data, events = dp.load_data(subjects=range(1,11))\n",
    "data, events = dp.choose_condition(data, events, 'inner speech')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Paramters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "explained_var = 0.98\n",
    "today = np.datetime_as_string(np.datetime64('today', 'D'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions:\n",
    " - plot original and reconstructed pca data\n",
    " - plot PCA\n",
    " - Plot difference between original and PCA reconstruction\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def save_raw(data,name):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(f'dataset/preprocessed/{name}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data preparation:\n",
    "filter relevant interval\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "f_data = dp.filter_interval(data, [1,3.5],256)\n",
    "cue_data = dp.filter_interval(data,[0.5,1], 256)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Standardize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#standardize data\n",
    "scaler = RobustScaler()\n",
    "cue_scaler = RobustScaler()\n",
    "s_data = scaler.fit_transform(f_data.reshape(-1, f_data.shape[-1])).reshape(f_data.shape)\n",
    "s_cue_data = cue_scaler.fit_transform(cue_data.reshape(-1, cue_data.shape[-1])).reshape(cue_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create PCA datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# reshape version\n",
    "rf_data = s_data.reshape(len(s_data), 128*640)\n",
    "rcue_data = s_cue_data.reshape(len(s_cue_data), 128*128)\n",
    "# mean version\n",
    "mean_data = np.mean(s_data, axis = 0)\n",
    "mean_cue = np.mean(s_cue_data,axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fit and apply PCA:\n",
    "Fit and apply on reshaped data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# fit and apply on reshaped data\n",
    "pca_1 = PCA(n_components=explained_var)\n",
    "pca_cue = PCA(explained_var)\n",
    "rf_pca = pca_1.fit_transform(rf_data)\n",
    "rcue_pca = pca_cue.fit_transform(rcue_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "fit on mean data, applied on time dimension"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# fit on mean data, applied on time dimension\n",
    "pca_2 = PCA(n_components=explained_var)\n",
    "pca_2.fit(mean_data)\n",
    "mean_time_pca = [pca_2.transform(elem) for elem in s_data]\n",
    "pca_2cue = PCA(n_components=explained_var)\n",
    "pca_2cue.fit(mean_cue)\n",
    "mean_time_cue_pca = [pca_2cue.transform(elem) for elem in s_cue_data]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "fit on transposed mean data, applied on channel dimension"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# fit on transposed mean data, applied on channel dimension\n",
    "pca_3 = PCA(n_components=explained_var)\n",
    "pca_3.fit(mean_data.T)\n",
    "mean_channel_pca = [pca_3.transform(elem.T).T for elem in s_data]\n",
    "pca_3cue = PCA(n_components=explained_var)\n",
    "pca_3cue.fit(mean_cue.T)\n",
    "mean_channel_cue_pca = [pca_3cue.transform(elem.T).T for elem in s_cue_data]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### save raw data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(2076, 26880)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel = np.array(mean_channel_pca)\n",
    "channel = channel.reshape(2076, 42*640)\n",
    "channel.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(2076, 4480)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = np.array(mean_time_pca)\n",
    "time = time.reshape(2076, 128*35)\n",
    "time.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#save_raw(rf_pca, f'reshape_pca{explained_var*100}-all')\n",
    "df_time = pd.DataFrame(time)\n",
    "df_time.to_csv(f'dataset/preprocessed/time_pca{int(explained_var*100)}_df_flat_128x35')\n",
    "#save_raw(channel,f'channel_pca{int(explained_var*100)}_df_flat_42x640')\n",
    "#save_raw(time, f'time_pca{int(explained_var*100)}_df_flat_128x35')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "df_channel = pd.DataFrame(channel)\n",
    "df_channel.to_csv(f'dataset/preprocessed/channel_pca{int(explained_var*100)}_df_flat_42x640')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rf_pca)\n",
    "df.to_csv(f'dataset/preprocessed/reshaped_pca{int(explained_var*100)}_df')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "(2076, 1603)"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pca"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fkock\\AppData\\Local\\Temp/ipykernel_9972/3463221478.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = df.append(df_cue)\n"
     ]
    }
   ],
   "source": [
    "df_cue = pd.DataFrame(rcue_pca)\n",
    "df_cue.to_csv(f'dataset/preprocessed/reshaped_pca{int(explained_var*100)}_df_cue')\n",
    "df_all = df.append(df_cue)\n",
    "df_all.to_csv(f'dataset/preprocessed/reshaped_pca{int(explained_var*100)}_df_e+c')\n",
    "label = pd.DataFrame(events[:,1])\n",
    "label.to_csv(f'dataset/preprocessed/label')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Tensorflow dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca_comp = rf_pca.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf_dataset = tf.data.Dataset.from_tensor_slices((rf_pca, events[:,1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_8224/922097663.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m rf_datasets = dp.preprocessing_pipeline(\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[0mrf_dataset\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m     functions = [lambda sample:(sample[0], tf.one_hot(sample[1], 4))#, # one-hot\n\u001B[0;32m      4\u001B[0m                  \u001B[1;31m#lambda sample: (tf.reshape(sample[0], (pca_comp, 1, 1)),\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m                                  \u001B[1;31m#sample[1])\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dp' is not defined"
     ]
    }
   ],
   "source": [
    "rf_datasets = dp.preprocessing_pipeline(\n",
    "    rf_dataset,\n",
    "    functions = [lambda sample:(sample[0], tf.one_hot(sample[1], 4))#, # one-hot\n",
    "                 #lambda sample: (tf.reshape(sample[0], (pca_comp, 1, 1)),\n",
    "                                 #sample[1])\n",
    "                 ],\n",
    "    args = [[]],\n",
    "    batch_size = 12\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_8224/806715867.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtime_dataset\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_tensor_slices\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmean_time_pca\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevents\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "time_dataset = tf.data.Dataset.from_tensor_slices((mean_time_pca, events[:,1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_8224/1216811700.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m time_datasets = dp.preprocessing_pipeline(\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[0mtime_dataset\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m     functions = [lambda sample:(sample[0], tf.one_hot(sample[1], 4)), # one-hot\n\u001B[0;32m      4\u001B[0m                 lambda sample: (tf.reshape(sample[0],(*sample[0].shape, 1)), sample[1])],\n\u001B[0;32m      5\u001B[0m     \u001B[0margs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dp' is not defined"
     ]
    }
   ],
   "source": [
    "time_datasets = dp.preprocessing_pipeline(\n",
    "    time_dataset,\n",
    "    functions = [lambda sample:(sample[0], tf.one_hot(sample[1], 4)), # one-hot\n",
    "                lambda sample: (tf.reshape(sample[0],(*sample[0].shape, 1)), sample[1])],\n",
    "    args = [[], []],\n",
    "    batch_size = 12\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_8224/1535918771.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mchannel_dataset\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_tensor_slices\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmean_channel_pca\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevents\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "channel_dataset = tf.data.Dataset.from_tensor_slices((mean_channel_pca, events[:,1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_8224/4078377797.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m channel_datasets = dp.preprocessing_pipeline(\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[0mchannel_dataset\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m     functions = [lambda sample:(sample[0], tf.one_hot(sample[1], 4)), # one-hot\n\u001B[0;32m      4\u001B[0m                 lambda sample: (tf.reshape(sample[0],(*sample[0].shape, 1)), sample[1])],\n\u001B[0;32m      5\u001B[0m     \u001B[0margs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dp' is not defined"
     ]
    }
   ],
   "source": [
    "channel_datasets = dp.preprocessing_pipeline(\n",
    "    channel_dataset,\n",
    "    functions = [lambda sample:(sample[0], tf.one_hot(sample[1], 4)), # one-hot\n",
    "                lambda sample: (tf.reshape(sample[0],(*sample[0].shape, 1)), sample[1])],\n",
    "    args = [[], []],\n",
    "    batch_size = 12\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### save datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# save dataset so that we can just load the preprocessed version next time\n",
    "today = np.datetime.today\n",
    "tf.data.experimental.save(rf_datasets,\n",
    "                          f'dataset/preprocessed/pca_all/{today}reshaped_pca{explained_var*100}train_ds_')\n",
    "tf.data.experimental.save(time_datasets,\n",
    "                          f'dataset/preprocessed/pca_all/{today}time_pca{explained_var*100}train_ds/')\n",
    "tf.data.experimental.save(channel_datasets,\n",
    "                          f'dataset/preprocessed/pca_all/{today}channel_pca{explained_var*100}train_ds')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}